{
    "cells":  [
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "# Automated Machine Learning\n",
                                     "\n",
                                     "## Forecasting away from training data\n",
                                     "\n",
                                     "This notebook demonstrates the full interface to the `forecast()` function. \n",
                                     "\n",
                                     "The best known and most frequent usage of `forecast` enables forecasting on test sets that immediately follows training data. \n",
                                     "\n",
                                     "However, in many use cases it is necessary to continue using the model for some time before retraining it. This happens especially in **high frequency forecasting** when forecasts need to be made more frequently than the model can be retrained. Examples are in Internet of Things and predictive cloud resource scaling.\n",
                                     "\n",
                                     "Here we show how to use the `forecast()` function when a time gap exists between training data and prediction period.\n",
                                     "\n",
                                     "Terminology:\n",
                                     "* forecast origin: the last period when the target value is known\n",
                                     "* forecast periods(s): the period(s) for which the value of the target is desired.\n",
                                     "* forecast horizon: the number of forecast periods\n",
                                     "* lookback: how many past periods (before forecast origin) the model function depends on. The larger of number of lags and length of rolling window.\n",
                                     "* prediction context: `lookback` periods immediately preceding the forecast origin\n",
                                     "\n",
                                     "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/automated-machine-learning/automl-forecasting-function.png)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Setup"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "Please make sure you have followed the `configuration.ipynb` notebook so that your ML workspace information is saved in the config file."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "import pandas as pd\n",
                                     "import numpy as np\n",
                                     "import logging\n",
                                     "import warnings\n",
                                     "\n",
                                     "from pandas.tseries.frequencies import to_offset\n",
                                     "\n",
                                     "# Squash warning messages for cleaner output in the notebook\n",
                                     "warnings.showwarning = lambda *args, **kwargs: None\n",
                                     "\n",
                                     "np.set_printoptions(precision=4, suppress=True, linewidth=120)"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "import azureml.core\n",
                                     "from azureml.core.workspace import Workspace\n",
                                     "from azureml.core.experiment import Experiment\n",
                                     "from azureml.train.automl import AutoMLConfig\n",
                                     "\n",
                                     "ws = Workspace.from_config()\n",
                                     "\n",
                                     "# choose a name for the run history container in the workspace\n",
                                     "experiment_name = \u0027automl-forecast-function-demo\u0027\n",
                                     "\n",
                                     "experiment = Experiment(ws, experiment_name)\n",
                                     "\n",
                                     "output = {}\n",
                                     "output[\u0027SDK version\u0027] = azureml.core.VERSION\n",
                                     "output[\u0027Subscription ID\u0027] = ws.subscription_id\n",
                                     "output[\u0027Workspace\u0027] = ws.name\n",
                                     "output[\u0027Resource Group\u0027] = ws.resource_group\n",
                                     "output[\u0027Location\u0027] = ws.location\n",
                                     "output[\u0027Run History Name\u0027] = experiment_name\n",
                                     "pd.set_option(\u0027display.max_colwidth\u0027, -1)\n",
                                     "outputDf = pd.DataFrame(data = output, index = [\u0027\u0027])\n",
                                     "outputDf.T"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Data\n",
                                     "For the demonstration purposes we will generate the data artificially and use them for the forecasting."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "TIME_COLUMN_NAME = \u0027date\u0027\n",
                                     "GRAIN_COLUMN_NAME = \u0027grain\u0027\n",
                                     "TARGET_COLUMN_NAME = \u0027y\u0027\n",
                                     "\n",
                                     "def get_timeseries(train_len: int,\n",
                                     "                   test_len: int,\n",
                                     "                   time_column_name: str,\n",
                                     "                   target_column_name: str,\n",
                                     "                   grain_column_name: str,\n",
                                     "                   grains: int = 1,\n",
                                     "                   freq: str = \u0027H\u0027):\n",
                                     "    \"\"\"\n",
                                     "    Return the time series of designed length.\n",
                                     "\n",
                                     "    :param train_len: The length of training data (one series).\n",
                                     "    :type train_len: int\n",
                                     "    :param test_len: The length of testing data (one series).\n",
                                     "    :type test_len: int\n",
                                     "    :param time_column_name: The desired name of a time column.\n",
                                     "    :type time_column_name: str\n",
                                     "    :param\n",
                                     "    :param grains: The number of grains.\n",
                                     "    :type grains: int\n",
                                     "    :param freq: The frequency string representing pandas offset.\n",
                                     "                 see https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
                                     "    :type freq: str\n",
                                     "    :returns: the tuple of train and test data sets.\n",
                                     "    :rtype: tuple\n",
                                     "\n",
                                     "    \"\"\"\n",
                                     "    data_train = []  # type: List[pd.DataFrame]\n",
                                     "    data_test = []  # type: List[pd.DataFrame]\n",
                                     "    data_length = train_len + test_len\n",
                                     "    for i in range(grains):\n",
                                     "        X = pd.DataFrame({\n",
                                     "            time_column_name: pd.date_range(start=\u00272000-01-01\u0027,\n",
                                     "                                            periods=data_length,\n",
                                     "                                            freq=freq),\n",
                                     "            target_column_name: np.arange(data_length).astype(float) + np.random.rand(data_length) + i*5,\n",
                                     "            \u0027ext_predictor\u0027: np.asarray(range(42, 42 + data_length)),\n",
                                     "            grain_column_name: np.repeat(\u0027g{}\u0027.format(i), data_length)\n",
                                     "        })\n",
                                     "        data_train.append(X[:train_len])\n",
                                     "        data_test.append(X[train_len:])\n",
                                     "    X_train = pd.concat(data_train)\n",
                                     "    y_train = X_train.pop(target_column_name).values\n",
                                     "    X_test = pd.concat(data_test)\n",
                                     "    y_test = X_test.pop(target_column_name).values\n",
                                     "    return X_train, y_train, X_test, y_test\n",
                                     "\n",
                                     "n_test_periods = 6\n",
                                     "n_train_periods = 30\n",
                                     "X_train, y_train, X_test, y_test = get_timeseries(train_len=n_train_periods,\n",
                                     "                                                  test_len=n_test_periods,\n",
                                     "                                                  time_column_name=TIME_COLUMN_NAME,\n",
                                     "                                                  target_column_name=TARGET_COLUMN_NAME,\n",
                                     "                                                  grain_column_name=GRAIN_COLUMN_NAME,\n",
                                     "                                                  grains=2)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "Let\u0027s see what the training data looks like."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "X_train.tail()"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# plot the example time series\n",
                                     "import matplotlib.pyplot as plt\n",
                                     "whole_data = X_train.copy()\n",
                                     "whole_data[\u0027y\u0027] = y_train\n",
                                     "for g in whole_data.groupby(\u0027grain\u0027):    \n",
                                     "    plt.plot(g[1][\u0027date\u0027].values, g[1][\u0027y\u0027].values, label=g[0])\n",
                                     "plt.legend()\n",
                                     "plt.show()"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Create the configuration and train a forecaster\n",
                                     "First generate the configuration, in which we:\n",
                                     "* Set metadata columns: target, time column and grain column names.\n",
                                     "* Ask for 10 iterations through models, last of which will represent the Ensemble of previous ones.\n",
                                     "* Validate our data using cross validation with rolling window method.\n",
                                     "* Set normalized root mean squared error as a metric to select the best model.\n",
                                     "\n",
                                     "* Finally, we set the task to be forecasting.\n",
                                     "* By default, we apply the lag lead operator and rolling window to the target value i.e. we use the previous values as a predictor for the future ones."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "lags = [1,2,3]\n",
                                     "rolling_window_length = 0 # don\u0027t do rolling windows\n",
                                     "max_horizon = n_test_periods\n",
                                     "time_series_settings = {    \n",
                                     "    \u0027time_column_name\u0027: TIME_COLUMN_NAME,\n",
                                     "    \u0027grain_column_names\u0027: [ GRAIN_COLUMN_NAME ],\n",
                                     "    \u0027max_horizon\u0027: max_horizon,\n",
                                     "    \u0027target_lags\u0027: lags\n",
                                     "}"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "Run the model selection and training process."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from azureml.core.workspace import Workspace\n",
                                     "from azureml.core.experiment import Experiment\n",
                                     "from azureml.train.automl import AutoMLConfig\n",
                                     "\n",
                                     "\n",
                                     "automl_config = AutoMLConfig(task=\u0027forecasting\u0027,\n",
                                     "                             debug_log=\u0027automl_forecasting_function.log\u0027,\n",
                                     "                             primary_metric=\u0027normalized_root_mean_squared_error\u0027,                             \n",
                                     "                             iterations=10,                             \n",
                                     "                             X=X_train,\n",
                                     "                             y=y_train,\n",
                                     "                             n_cross_validations=3,\n",
                                     "                             verbosity = logging.INFO,\n",
                                     "                             **time_series_settings)\n",
                                     "\n",
                                     "local_run = experiment.submit(automl_config, show_output=True)\n",
                                     "\n",
                                     "# Retrieve the best model to use it further.\n",
                                     "_, fitted_model = local_run.get_output()"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Forecasting from the trained model"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "In this section we will review the `forecast` interface for two main scenarios: forecasting right after the training data, and the more complex interface for forecasting when there is a gap (in the time sense) between training and testing data."
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "### X_train is directly followed by the X_test\n",
                                     "\n",
                                     "Let\u0027s first consider the case when the prediction period immediately follows the training data. This is typical in scenarios where we have the time to retrain the model every time we wish to forecast. Forecasts that are made on daily and slower cadence typically fall into this category. Retraining the model every time benefits the accuracy because the most recent data is often the most informative.\n",
                                     "\n",
                                     "![Forecasting after training](forecast_function_at_train.png)\n",
                                     "\n",
                                     "The `X_test` and `y_query` below, taken together, form the **forecast request**. The two are interpreted as aligned - `y_query` could actally be a column in `X_test`. `NaN`s in `y_query` are the question marks. These will be filled with the forecasts.\n",
                                     "\n",
                                     "When the forecast period immediately follows the training period, the models retain the last few points of data. You can simply fill `y_query` filled with question marks - the model has the data for the lookback already.\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "#### Typical path: X_test is known, forecast all upcoming periods"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# The data set contains hourly data, the training set ends at 01/02/2000 at 05:00\n",
                                     "\n",
                                     "# These are predictions we are asking the model to make (does not contain thet target column y),\n",
                                     "# for 6 periods beginning with 2000-01-02 06:00, which immediately follows the training data\n",
                                     "X_test"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "y_query = np.repeat(np.NaN, X_test.shape[0])\n",
                                     "y_pred_no_gap, xy_nogap =  fitted_model.forecast(X_test, y_query)\n",
                                     "\n",
                                     "# xy_nogap contains the predictions in the _automl_target_col column.\n",
                                     "# Those same numbers are output in y_pred_no_gap\n",
                                     "xy_nogap"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "#### Distribution forecasts\n",
                                     "\n",
                                     "Often the figure of interest is not just the point prediction, but the prediction at some quantile of the distribution. \n",
                                     "This arises when the forecast is used to control some kind of inventory, for example of grocery items of virtual machines for a cloud service. In such case, the control point is usually something like \"we want the item to be in stock and not run out 99% of the time\". This is called a \"service level\". Here is how you get quantile forecasts."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# specify which quantiles you would like \n",
                                     "fitted_model.quantiles = [0.01, 0.5, 0.95]\n",
                                     "# use forecast_quantiles function, not the forecast() one\n",
                                     "y_pred_quantiles =  fitted_model.forecast_quantiles(X_test, y_query)\n",
                                     "\n",
                                     "# it all nicely aligns column-wise\n",
                                     "pd.concat([X_test.reset_index(), pd.DataFrame({\u0027query\u0027 : y_query}), y_pred_quantiles], axis=1)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "#### Destination-date forecast: \"just do something\"\n",
                                     "\n",
                                     "In some scenarios, the X_test is not known. The forecast is likely to be weak, becaus eit is missing contemporaneous predictors, which we will need to impute. If you still wish to predict forward under the assumption that the last known values will be carried forward, you can forecast out to \"destination date\". The destination date still needs to fit within the maximum horizon from training."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# We will take the destination date as a last date in the test set.\n",
                                     "dest = max(X_test[TIME_COLUMN_NAME])\n",
                                     "y_pred_dest, xy_dest = fitted_model.forecast(forecast_destination=dest)\n",
                                     "\n",
                                     "# This form also shows how we imputed the predictors which were not given. (Not so well! Use with caution!)\n",
                                     "xy_dest"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Forecasting away from training data\n",
                                     "\n",
                                     "Suppose we trained a model, some time passed, and now we want to apply the model without re-training. If the model \"looks back\" -- uses previous values of the target -- then we somehow need to provide those values to the model.\n",
                                     "\n",
                                     "![Forecasting after training](forecast_function_away_from_train.png)\n",
                                     "\n",
                                     "The notion of forecast origin comes into play: the forecast origin is **the last period for which we have seen the target value**. This applies per grain, so each grain can have a different forecast origin. \n",
                                     "\n",
                                     "The part of data before the forecast origin is the **prediction context**. To provide the context values the model needs when it looks back, we pass definite values in `y_test` (aligned with corresponding times in `X_test`)."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# generate the same kind of test data we trained on, \n",
                                     "# but now make the train set much longer, so that the test set will be in the future\n",
                                     "X_context, y_context, X_away, y_away = get_timeseries(train_len=42, # train data was 30 steps long\n",
                                     "                                      test_len=4,\n",
                                     "                                      time_column_name=TIME_COLUMN_NAME,\n",
                                     "                                      target_column_name=TARGET_COLUMN_NAME,\n",
                                     "                                      grain_column_name=GRAIN_COLUMN_NAME,\n",
                                     "                                      grains=2)\n",
                                     "\n",
                                     "# end of the data we trained on\n",
                                     "print(X_train.groupby(GRAIN_COLUMN_NAME)[TIME_COLUMN_NAME].max())\n",
                                     "# start of the data we want to predict on\n",
                                     "print(X_away.groupby(GRAIN_COLUMN_NAME)[TIME_COLUMN_NAME].min())"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "There is a gap of 12 hours between end of training and beginning of `X_away`. (It looks like 13 because all timestamps point to the start of the one hour periods.) Using only `X_away` will fail without adding context data for the model to consume."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "try: \n",
                                     "    y_query = y_away.copy()\n",
                                     "    y_query.fill(np.NaN)\n",
                                     "    y_pred_away, xy_away = fitted_model.forecast(X_away, y_query)\n",
                                     "    xy_away\n",
                                     "except Exception as e:\n",
                                     "    print(e)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "How should we read that eror message? The forecast origin is at the last time themodel saw an actual values of `y` (the target). That was at the end of the training data! Because the model received all `NaN` (and not an actual target value), it is attempting to forecast from the end of training data. But the requested forecast periods are past the maximum horizon. We need to provide a define `y` value to establish the forecast origin.\n",
                                     "\n",
                                     "We will use this helper function to take the required amount of context from the data preceding the testing data. It\u0027s definition is intentionally simplified to keep the idea in the clear."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "def make_forecasting_query(fulldata, time_column_name, target_column_name, forecast_origin, horizon, lookback):\n",
                                     "\n",
                                     "    \"\"\"\n",
                                     "    This function will take the full dataset, and create the query\n",
                                     "    to predict all values of the grain from the `forecast_origin`\n",
                                     "    forward for the next `horizon` horizons. Context from previous\n",
                                     "    `lookback` periods will be included.\n",
                                     "\n",
                                     "    \n",
                                     "\n",
                                     "    fulldata: pandas.DataFrame           a time series dataset. Needs to contain X and y.\n",
                                     "    time_column_name: string             which column (must be in fulldata) is the time axis\n",
                                     "    target_column_name: string           which column (must be in fulldata) is to be forecast\n",
                                     "    forecast_origin: datetime type       the last time we (pretend to) have target values \n",
                                     "    horizon: timedelta                   how far forward, in time units (not periods)\n",
                                     "    lookback: timedelta                  how far back does the model look?\n",
                                     "\n",
                                     "    Example:\n",
                                     "\n",
                                     "\n",
                                     "    ```\n",
                                     "\n",
                                     "    forecast_origin = pd.to_datetime(\u00272012-09-01\u0027) + pd.DateOffset(days=5) # forecast 5 days after end of training\n",
                                     "    print(forecast_origin)\n",
                                     "\n",
                                     "    X_query, y_query = make_forecasting_query(data, \n",
                                     "                       forecast_origin = forecast_origin,\n",
                                     "                       horizon = pd.DateOffset(days=7), # 7 days into the future\n",
                                     "                       lookback = pd.DateOffset(days=1), # model has lag 1 period (day)\n",
                                     "                      )\n",
                                     "\n",
                                     "    ```\n",
                                     "    \"\"\"\n",
                                     "\n",
                                     "    X_past = fulldata[ (fulldata[ time_column_name ] \u003e forecast_origin - lookback) \u0026\n",
                                     "                       (fulldata[ time_column_name ] \u003c= forecast_origin)\n",
                                     "                     ]\n",
                                     "\n",
                                     "    X_future = fulldata[ (fulldata[ time_column_name ] \u003e forecast_origin) \u0026\n",
                                     "                         (fulldata[ time_column_name ] \u003c= forecast_origin + horizon)\n",
                                     "                       ]\n",
                                     "\n",
                                     "    y_past = X_past.pop(target_column_name).values.astype(np.float)\n",
                                     "    y_future = X_future.pop(target_column_name).values.astype(np.float)\n",
                                     "\n",
                                     "    # Now take y_future and turn it into question marks\n",
                                     "    y_query = y_future.copy().astype(np.float)  # because sometimes life hands you an int\n",
                                     "    y_query.fill(np.NaN)\n",
                                     "\n",
                                     "\n",
                                     "    print(\"X_past is \" + str(X_past.shape) + \" - shaped\")\n",
                                     "    print(\"X_future is \" + str(X_future.shape) + \" - shaped\")\n",
                                     "    print(\"y_past is \" + str(y_past.shape) + \" - shaped\")\n",
                                     "    print(\"y_query is \" + str(y_query.shape) + \" - shaped\")\n",
                                     "\n",
                                     "\n",
                                     "    X_pred = pd.concat([X_past, X_future])\n",
                                     "    y_pred = np.concatenate([y_past, y_query])\n",
                                     "    return X_pred, y_pred"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "Let\u0027s see where the context data ends - it ends, by construction, just before the testing data starts."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "print(X_context.groupby(GRAIN_COLUMN_NAME)[TIME_COLUMN_NAME].agg([\u0027min\u0027,\u0027max\u0027,\u0027count\u0027]))\n",
                                     "print(   X_away.groupby(GRAIN_COLUMN_NAME)[TIME_COLUMN_NAME].agg([\u0027min\u0027,\u0027max\u0027,\u0027count\u0027]))\n",
                                     "X_context.tail(5)"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Since the length of the lookback is 3, \n",
                                     "# we need to add 3 periods from the context to the request\n",
                                     "# so that the model has the data it needs\n",
                                     "\n",
                                     "# Put the X and y back together for a while. \n",
                                     "# They like each other and it makes them happy.\n",
                                     "X_context[TARGET_COLUMN_NAME] = y_context\n",
                                     "X_away[TARGET_COLUMN_NAME] = y_away\n",
                                     "fulldata = pd.concat([X_context, X_away])\n",
                                     "\n",
                                     "# forecast origin is the last point of data, which is one 1-hr period before test\n",
                                     "forecast_origin = X_away[TIME_COLUMN_NAME].min() - pd.DateOffset(hours=1)\n",
                                     "# it is indeed the last point of the context\n",
                                     "assert forecast_origin == X_context[TIME_COLUMN_NAME].max()\n",
                                     "print(\"Forecast origin: \" + str(forecast_origin))\n",
                                     "      \n",
                                     "# the model uses lags and rolling windows to look back in time\n",
                                     "n_lookback_periods = max(max(lags), rolling_window_length)\n",
                                     "lookback = pd.DateOffset(hours=n_lookback_periods)\n",
                                     "\n",
                                     "horizon = pd.DateOffset(hours=max_horizon)\n",
                                     "\n",
                                     "# now make the forecast query from context (refer to figure)\n",
                                     "X_pred, y_pred = make_forecasting_query(fulldata, TIME_COLUMN_NAME, TARGET_COLUMN_NAME,\n",
                                     "                                        forecast_origin, horizon, lookback)\n",
                                     "\n",
                                     "# show the forecast request aligned\n",
                                     "X_show = X_pred.copy()\n",
                                     "X_show[TARGET_COLUMN_NAME] = y_pred\n",
                                     "X_show"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "Note that the forecast origin is at 17:00 for both grains, and periods from 18:00 are to be forecast."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Now everything works\n",
                                     "y_pred_away, xy_away = fitted_model.forecast(X_pred, y_pred)\n",
                                     "\n",
                                     "# show the forecast aligned\n",
                                     "X_show = xy_away.reset_index()\n",
                                     "# without the generated features\n",
                                     "X_show[[\u0027date\u0027, \u0027grain\u0027, \u0027ext_predictor\u0027, \u0027_automl_target_col\u0027]]\n",
                                     "# prediction is in _automl_target_col"
                                 ]
                  }
              ],
    "metadata":  {
                     "authors":  [
                                     {
                                         "name":  "erwright, nirovins"
                                     }
                                 ],
                     "kernelspec":  {
                                        "display_name":  "Python 3.6 - AzureML",
                                        "language":  "python",
                                        "name":  "python3-azureml"
                                    },
                     "language_info":  {
                                           "codemirror_mode":  {
                                                                   "name":  "ipython",
                                                                   "version":  3
                                                               },
                                           "file_extension":  ".py",
                                           "mimetype":  "text/x-python",
                                           "name":  "python",
                                           "nbconvert_exporter":  "python",
                                           "pygments_lexer":  "ipython3",
                                           "version":  "3.6.7"
                                       },
                     "categories":  [
                                        "how-to-use-azureml",
                                        "automated-machine-learning"
                                    ]
                 },
    "nbformat":  4,
    "nbformat_minor":  2
}