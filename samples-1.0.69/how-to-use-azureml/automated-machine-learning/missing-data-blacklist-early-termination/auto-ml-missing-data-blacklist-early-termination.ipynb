{
    "cells":  [
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "Copyright (c) Microsoft Corporation. All rights reserved.\n",
                                     "\n",
                                     "Licensed under the MIT License."
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/NotebookVM/how-to-use-azureml/automated-machine-learning/missing-data-blacklist-early-termination/auto-ml-missing-data-blacklist-early-termination.png)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "# Automated Machine Learning\n",
                                     "_**Blacklisting Models, Early Termination, and Handling Missing Data**_\n",
                                     "\n",
                                     "## Contents\n",
                                     "1. [Introduction](#Introduction)\n",
                                     "1. [Setup](#Setup)\n",
                                     "1. [Data](#Data)\n",
                                     "1. [Train](#Train)\n",
                                     "1. [Results](#Results)\n",
                                     "1. [Test](#Test)\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Introduction\n",
                                     "In this example we use the scikit-learn\u0027s [digit dataset](http://scikit-learn.org/stable/datasets/index.html#optical-recognition-of-handwritten-digits-dataset) to showcase how you can use AutoML for handling missing values in data. We also provide a stopping metric indicating a target for the primary metrics so that AutoML can terminate the run without necessarly going through all the iterations. Finally, if you want to avoid a certain pipeline, we allow you to specify a blacklist of algorithms that AutoML will ignore for this run.\n",
                                     "\n",
                                     "Make sure you have executed the [configuration](../../../configuration.ipynb) before running this notebook.\n",
                                     "\n",
                                     "In this notebook you will learn how to:\n",
                                     "1. Create an `Experiment` in an existing `Workspace`.\n",
                                     "2. Configure AutoML using `AutoMLConfig`.\n",
                                     "3. Train the model.\n",
                                     "4. Explore the results.\n",
                                     "5. Viewing the engineered names for featurized data and featurization summary for all raw features.\n",
                                     "6. Test the best fitted model.\n",
                                     "\n",
                                     "In addition this notebook showcases the following features\n",
                                     "- **Blacklisting** certain pipelines\n",
                                     "- Specifying **target metrics** to indicate stopping criteria\n",
                                     "- Handling **missing data** in the input"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Setup\n",
                                     "\n",
                                     "As part of the setup you have already created an Azure ML `Workspace` object. For AutoML you will need to create an `Experiment` object, which is a named object in a `Workspace` used to run experiments."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "import logging\n",
                                     "\n",
                                     "from matplotlib import pyplot as plt\n",
                                     "import numpy as np\n",
                                     "import pandas as pd\n",
                                     "from sklearn import datasets\n",
                                     "\n",
                                     "import azureml.core\n",
                                     "from azureml.core.experiment import Experiment\n",
                                     "from azureml.core.workspace import Workspace\n",
                                     "from azureml.train.automl import AutoMLConfig"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "ws = Workspace.from_config()\n",
                                     "\n",
                                     "# Choose a name for the experiment.\n",
                                     "experiment_name = \u0027automl-local-missing-data\u0027\n",
                                     "\n",
                                     "experiment = Experiment(ws, experiment_name)\n",
                                     "\n",
                                     "output = {}\n",
                                     "output[\u0027SDK version\u0027] = azureml.core.VERSION\n",
                                     "output[\u0027Subscription ID\u0027] = ws.subscription_id\n",
                                     "output[\u0027Workspace\u0027] = ws.name\n",
                                     "output[\u0027Resource Group\u0027] = ws.resource_group\n",
                                     "output[\u0027Location\u0027] = ws.location\n",
                                     "output[\u0027Experiment Name\u0027] = experiment.name\n",
                                     "pd.set_option(\u0027display.max_colwidth\u0027, -1)\n",
                                     "outputDf = pd.DataFrame(data = output, index = [\u0027\u0027])\n",
                                     "outputDf.T"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Data"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "digits = datasets.load_digits()\n",
                                     "X_train = digits.data[10:,:]\n",
                                     "y_train = digits.target[10:]\n",
                                     "\n",
                                     "# Add missing values in 75% of the lines.\n",
                                     "missing_rate = 0.75\n",
                                     "n_missing_samples = int(np.floor(X_train.shape[0] * missing_rate))\n",
                                     "missing_samples = np.hstack((np.zeros(X_train.shape[0] - n_missing_samples, dtype=np.bool), np.ones(n_missing_samples, dtype=np.bool)))\n",
                                     "rng = np.random.RandomState(0)\n",
                                     "rng.shuffle(missing_samples)\n",
                                     "missing_features = rng.randint(0, X_train.shape[1], n_missing_samples)\n",
                                     "X_train[np.where(missing_samples)[0], missing_features] = np.nan"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "df = pd.DataFrame(data = X_train)\n",
                                     "df[\u0027Label\u0027] = pd.Series(y_train, index=df.index)\n",
                                     "df.head()"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Train\n",
                                     "\n",
                                     "Instantiate an `AutoMLConfig` object to specify the settings and data used to run the experiment.  This includes setting `experiment_exit_score`, which should cause the run to complete before the `iterations` count is reached.\n",
                                     "\n",
                                     "|Property|Description|\n",
                                     "|-|-|\n",
                                     "|**task**|classification or regression|\n",
                                     "|**primary_metric**|This is the metric that you want to optimize. Classification supports the following primary metrics: \u003cbr\u003e\u003ci\u003eaccuracy\u003c/i\u003e\u003cbr\u003e\u003ci\u003eAUC_weighted\u003c/i\u003e\u003cbr\u003e\u003ci\u003eaverage_precision_score_weighted\u003c/i\u003e\u003cbr\u003e\u003ci\u003enorm_macro_recall\u003c/i\u003e\u003cbr\u003e\u003ci\u003eprecision_score_weighted\u003c/i\u003e|\n",
                                     "|**iteration_timeout_minutes**|Time limit in minutes for each iteration.|\n",
                                     "|**iterations**|Number of iterations. In each iteration AutoML trains a specific pipeline with the data.|\n",
                                     "|**preprocess**|Setting this to *True* enables AutoML to perform preprocessing on the input to handle *missing data*, and to perform some common *feature extraction*.|\n",
                                     "|**experiment_exit_score**|*double* value indicating the target for *primary_metric*. \u003cbr\u003eOnce the target is surpassed the run terminates.|\n",
                                     "|**blacklist_models**|*List* of *strings* indicating machine learning algorithms for AutoML to avoid in this run.\u003cbr\u003e\u003cbr\u003e Allowed values for **Classification**\u003cbr\u003e\u003ci\u003eLogisticRegression\u003c/i\u003e\u003cbr\u003e\u003ci\u003eSGD\u003c/i\u003e\u003cbr\u003e\u003ci\u003eMultinomialNaiveBayes\u003c/i\u003e\u003cbr\u003e\u003ci\u003eBernoulliNaiveBayes\u003c/i\u003e\u003cbr\u003e\u003ci\u003eSVM\u003c/i\u003e\u003cbr\u003e\u003ci\u003eLinearSVM\u003c/i\u003e\u003cbr\u003e\u003ci\u003eKNN\u003c/i\u003e\u003cbr\u003e\u003ci\u003eDecisionTree\u003c/i\u003e\u003cbr\u003e\u003ci\u003eRandomForest\u003c/i\u003e\u003cbr\u003e\u003ci\u003eExtremeRandomTrees\u003c/i\u003e\u003cbr\u003e\u003ci\u003eLightGBM\u003c/i\u003e\u003cbr\u003e\u003ci\u003eGradientBoosting\u003c/i\u003e\u003cbr\u003e\u003ci\u003eTensorFlowDNN\u003c/i\u003e\u003cbr\u003e\u003ci\u003eTensorFlowLinearClassifier\u003c/i\u003e\u003cbr\u003e\u003cbr\u003eAllowed values for **Regression**\u003cbr\u003e\u003ci\u003eElasticNet\u003c/i\u003e\u003cbr\u003e\u003ci\u003eGradientBoosting\u003c/i\u003e\u003cbr\u003e\u003ci\u003eDecisionTree\u003c/i\u003e\u003cbr\u003e\u003ci\u003eKNN\u003c/i\u003e\u003cbr\u003e\u003ci\u003eLassoLars\u003c/i\u003e\u003cbr\u003e\u003ci\u003eSGD\u003c/i\u003e\u003cbr\u003e\u003ci\u003eRandomForest\u003c/i\u003e\u003cbr\u003e\u003ci\u003eExtremeRandomTrees\u003c/i\u003e\u003cbr\u003e\u003ci\u003eLightGBM\u003c/i\u003e\u003cbr\u003e\u003ci\u003eTensorFlowLinearRegressor\u003c/i\u003e\u003cbr\u003e\u003ci\u003eTensorFlowDNN\u003c/i\u003e|\n",
                                     "|**X**|(sparse) array-like, shape = [n_samples, n_features]|\n",
                                     "|**y**|(sparse) array-like, shape = [n_samples, ], Multi-class targets.|"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "automl_config = AutoMLConfig(task = \u0027classification\u0027,\n",
                                     "                             debug_log = \u0027automl_errors.log\u0027,\n",
                                     "                             primary_metric = \u0027AUC_weighted\u0027,\n",
                                     "                             iteration_timeout_minutes = 60,\n",
                                     "                             iterations = 20,\n",
                                     "                             preprocess = True,\n",
                                     "                             experiment_exit_score = 0.9984,\n",
                                     "                             blacklist_models = [\u0027KNN\u0027,\u0027LinearSVM\u0027],\n",
                                     "                             verbosity = logging.INFO,\n",
                                     "                             X = X_train, \n",
                                     "                             y = y_train)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "Call the `submit` method on the experiment object and pass the run configuration. Execution of local runs is synchronous. Depending on the data and the number of iterations this can run for a while.\n",
                                     "In this example, we specify `show_output = True` to print currently running iterations to the console."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "local_run = experiment.submit(automl_config, show_output = True)"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "local_run"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Results"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "#### Widget for Monitoring Runs\n",
                                     "\n",
                                     "The widget will first report a \"loading\" status while running the first iteration. After completing the first iteration, an auto-updating graph and table will be shown. The widget will refresh once per minute, so you should see the graph update as child runs complete.\n",
                                     "\n",
                                     "**Note:** The widget displays a link at the bottom. Use this link to open a web interface to explore the individual run details."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from azureml.widgets import RunDetails\n",
                                     "RunDetails(local_run).show() "
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "\n",
                                     "#### Retrieve All Child Runs\n",
                                     "You can also use SDK methods to fetch all the child runs and see individual metrics that we log."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "children = list(local_run.get_children())\n",
                                     "metricslist = {}\n",
                                     "for run in children:\n",
                                     "    properties = run.get_properties()\n",
                                     "    metrics = {k: v for k, v in run.get_metrics().items() if isinstance(v, float)}\n",
                                     "    metricslist[int(properties[\u0027iteration\u0027])] = metrics\n",
                                     "\n",
                                     "rundata = pd.DataFrame(metricslist).sort_index(1)\n",
                                     "rundata"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "### Retrieve the Best Model\n",
                                     "\n",
                                     "Below we select the best pipeline from our iterations. The `get_output` method returns the best run and the fitted model. The Model includes the pipeline and any pre-processing.  Overloads on `get_output` allow you to retrieve the best run and fitted model for *any* logged metric or for a particular *iteration*."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "best_run, fitted_model = local_run.get_output()"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "#### Best Model Based on Any Other Metric\n",
                                     "Show the run and the model which has the smallest `accuracy` value:"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# lookup_metric = \"accuracy\"\n",
                                     "# best_run, fitted_model = local_run.get_output(metric = lookup_metric)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "#### Model from a Specific Iteration\n",
                                     "Show the run and the model from the third iteration:"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# iteration = 3\n",
                                     "# best_run, fitted_model = local_run.get_output(iteration = iteration)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "#### View the engineered names for featurized data\n",
                                     "Below we display the engineered feature names generated for the featurized data using the preprocessing featurization."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "fitted_model.named_steps[\u0027datatransformer\u0027].get_engineered_feature_names()"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "#### View the featurization summary\n",
                                     "Below we display the featurization that was performed on different raw features in the user data. For each raw feature in the user data, the following information is displayed:-\n",
                                     "- Raw feature name\n",
                                     "- Number of engineered features formed out of this raw feature\n",
                                     "- Type detected\n",
                                     "- If feature was dropped\n",
                                     "- List of feature transformations for the raw feature"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Get the featurization summary as a list of JSON\n",
                                     "featurization_summary = fitted_model.named_steps[\u0027datatransformer\u0027].get_featurization_summary()\n",
                                     "# View the featurization summary as a pandas dataframe\n",
                                     "pd.DataFrame.from_records(featurization_summary)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Test"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "digits = datasets.load_digits()\n",
                                     "X_test = digits.data[:10, :]\n",
                                     "y_test = digits.target[:10]\n",
                                     "images = digits.images[:10]\n",
                                     "\n",
                                     "# Randomly select digits and test.\n",
                                     "for index in np.random.choice(len(y_test), 2, replace = False):\n",
                                     "    print(index)\n",
                                     "    predicted = fitted_model.predict(X_test[index:index + 1])[0]\n",
                                     "    label = y_test[index]\n",
                                     "    title = \"Label value = %d  Predicted value = %d \" % (label, predicted)\n",
                                     "    fig = plt.figure(1, figsize=(3,3))\n",
                                     "    ax1 = fig.add_axes((0,0,.8,.8))\n",
                                     "    ax1.set_title(title)\n",
                                     "    plt.imshow(images[index], cmap = plt.cm.gray_r, interpolation = \u0027nearest\u0027)\n",
                                     "    plt.show()\n"
                                 ]
                  }
              ],
    "metadata":  {
                     "authors":  [
                                     {
                                         "name":  "savitam"
                                     }
                                 ],
                     "kernelspec":  {
                                        "display_name":  "Python 3.6 - AzureML",
                                        "language":  "python",
                                        "name":  "python3-azureml"
                                    },
                     "language_info":  {
                                           "codemirror_mode":  {
                                                                   "name":  "ipython",
                                                                   "version":  3
                                                               },
                                           "file_extension":  ".py",
                                           "mimetype":  "text/x-python",
                                           "name":  "python",
                                           "nbconvert_exporter":  "python",
                                           "pygments_lexer":  "ipython3",
                                           "version":  "3.6.6"
                                       },
                     "categories":  [
                                        "how-to-use-azureml",
                                        "automated-machine-learning"
                                    ]
                 },
    "nbformat":  4,
    "nbformat_minor":  2
}