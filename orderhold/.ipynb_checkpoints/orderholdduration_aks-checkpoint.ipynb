{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading modules and  packages\n",
    "import logging\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.externals import joblib\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "from azureml.core import Experiment\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.image import ContainerImage\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle as pkl\n",
    "from sklearn.linear_model import Ridge\n",
    "from azureml.core.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace.create(name='xm-ml-workspace', subscription_id='be564fde-136b-4709-b7b6-abfc0bdfc134', resource_group='xm-ml')\n"
     ]
    }
   ],
   "source": [
    "print(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model orderholdaks\n"
     ]
    }
   ],
   "source": [
    "#registering the model\n",
    "model = Model.register(model_name = \"orderholdaks\",\n",
    "                       model_path = \"data/orderhold.pkl\",\n",
    "                       tags = {\"key\": \"3\",\"classification\": \"orderhold\",\"version\":\"2\"},\n",
    "                       description = \"orderhold prediction\",\n",
    "                       workspace = ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orderholdaks\n"
     ]
    }
   ],
   "source": [
    "print(model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import azureml.train.automl\n",
    "from sklearn.externals import joblib\n",
    "from azureml.core.model import Model\n",
    "\n",
    "from inference_schema.schema_decorators import input_schema, output_schema\n",
    "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
    "from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\n",
    "\n",
    "\n",
    "input_sample = pd.DataFrame(data=[{\"NUM_PORTIN\":1,\"THIRD_PARTY_ID_SCORE\":413,\"FIRST_PARTY_ID_SCORE\":423,\"MAKE1\":\"Apple\",\"MONTHLYRECURRINGCHARGE\":45.0,\"HOUR_OF_DAY\":23,\"TOTAL_PRICE\":0.0,\"PRICE1\":0.0,\"ONETIMECHARGE\":0.0,\"IDA_RESULT\":\"GREEN\",\"MODEL1\":\"iPhone 6 Plus\",\"INSTALLMENT_AMOUNT\":0.0,\"IS_EXISTING_CUSTOMER\":\"N\"}])\n",
    "output_sample = np.array([0])\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # This name is model.id of model that we want to deploy deserialize the model file back\n",
    "    # into a sklearn model\n",
    "    model_path = Model.get_model_path(model_name = 'orderholdaks')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "@input_schema('data', PandasParameterType(input_sample))\n",
    "@output_schema(NumpyParameterType(output_sample))\n",
    "def run(data):\n",
    "    try:\n",
    "        result = model.predict(data)\n",
    "        if result ==0:\n",
    "            result = 'FAST'\n",
    "            print('FAST')\n",
    "        elif result ==1:\n",
    "            result = 'ON TARGET'\n",
    "            print('ON TARGET')\n",
    "        else:\n",
    "            result = 'SLOW'\n",
    "            print('SLOW')\n",
    "        print('result') \n",
    "        fraud_status =[]\n",
    "        fraud_status.append(result)\n",
    "        return fraud_status\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({\"error\": result})\n",
    "    return json.dumps({\"result\": result.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create environment file\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.model import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.externals import joblib\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "from azureml.core import Experiment\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.image import ContainerImage\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle as pkl\n",
    "durationenv = CondaDependencies()\n",
    "durationenv.add_conda_package(\"scikit-learn\")\n",
    "durationenv.add_conda_package(\"numpy\")\n",
    "durationenv.add_conda_package(\"scipy\")\n",
    "durationenv.add_conda_package(\"pandas\")\n",
    "durationenv.add_conda_package(\"py-xgboost<=0.80\")\n",
    "durationenv.add_pip_package(\"azureml-defaults\")\n",
    "durationenv.add_pip_package(\"azureml-train-automl==1.0.55\")\n",
    "durationenv.add_pip_package(\"azureml-core==1.0.55\")\n",
    "durationenv.add_pip_package(\"inference-schema\")\n",
    "durationenv.conda_dependencies_file_path=\"data/env_dependencies.json\"\n",
    "with open(\"orddurationenv.yml\",\"w\") as f:\n",
    "    f.write(durationenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ComputeTargetException",
     "evalue": "ComputeTargetException:\n\tMessage: ComputeTargetNotFound: Compute Target with name xm-ml-er-aks246202029b not found in provided workspace\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"ComputeTargetNotFound: Compute Target with name xm-ml-er-aks246202029b not found in provided workspace\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mComputeTargetException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-276531f9a7ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAksCompute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComputeTarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0maks_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'xm-ml-er-aks246202029b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maks_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAksCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maks_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/compute/compute.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, workspace, name)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 raise ComputeTargetException('ComputeTargetNotFound: Compute Target with name {} not found in '\n\u001b[0;32m---> 79\u001b[0;31m                                              'provided workspace'.format(name))\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mComputeTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mComputeTargetException\u001b[0m: ComputeTargetException:\n\tMessage: ComputeTargetNotFound: Compute Target with name xm-ml-er-aks246202029b not found in provided workspace\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"ComputeTargetNotFound: Compute Target with name xm-ml-er-aks246202029b not found in provided workspace\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "aks_name = 'xm-ml-er-aks246202029b' \n",
    "aks_target = AksCompute(ws, aks_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multiservice'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(aks_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Running..........................................................\n",
      "Succeeded\n",
      "Image creation operation finished for image orderholdlatest:2, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "# creating a container image\n",
    "from azureml.core.image import Image, ContainerImage\n",
    "image_config = ContainerImage.image_configuration(runtime= \"python\",\n",
    "                                 execution_script=\"score.py\",\n",
    "                                 conda_file=\"orddurationenv.yml\",\n",
    "                                 tags = {\"key\": \"1\",\"image\": \"orderholdduration\"},\n",
    "                                 description = \"orderholdv2\")\n",
    "image = Image.create(name = \"orderholdlatest\",\n",
    "                     # this is the model object \n",
    "                     models = [model],\n",
    "                     image_config = image_config, \n",
    "                     workspace = ws)\n",
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create inference config\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "inference_config = InferenceConfig(runtime= \"python\", \n",
    "                                   entry_script=\"score.py\",\n",
    "                                   conda_file=\"orddurationenv.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running......................................................................................................\n",
      "SucceededAKS service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n",
      "/bin/bash: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2019-10-24T15:01:04,433220992+00:00 - iot-server/run \n",
      "2019-10-24T15:01:04,433302192+00:00 - rsyslog/run \n",
      "bash: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "2019-10-24T15:01:04,443205635+00:00 - gunicorn/run \n",
      "2019-10-24T15:01:04,446027547+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "/bin/bash: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2019-10-24T15:01:04,511331226+00:00 - iot-server/finish 1 0\n",
      "2019-10-24T15:01:04,512643332+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (11)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 41\n",
      "Initialized PySpark session.\n",
      "Initializing logger\n",
      "Starting up app insights client\n",
      "Starting up request id generator\n",
      "Starting up app insight hooks\n",
      "Invoking user's init function\n",
      "2019-10-24 15:01:06,896 | azureml.core.run | DEBUG | Could not load run context RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException None\n",
      "\tErrorResponse {\"error\": {\"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"}}, switching offline: False\n",
      "2019-10-24 15:01:06,897 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\n",
      "2019-10-24 15:01:06,897 | azureml.core.model | DEBUG | RunEnvironmentException: RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException None\n",
      "\tErrorResponse {\"error\": {\"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"}}\n",
      "\tErrorResponse {\"error\": {\"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"}}\n",
      "2019-10-24 15:01:06,898 | azureml.core.model | DEBUG | version is None. Latest version is 3\n",
      "2019-10-24 15:01:06,898 | azureml.core.model | DEBUG | Found model path at azureml-models/orderholdaks/3/orderhold.pkl\n",
      "Users's init has completed successfully\n",
      "Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#service deployment\n",
    "from azureml.core.webservice import AksWebservice, Webservice\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.image import Image, ContainerImage\n",
    "\n",
    "\n",
    "aks_target = AksCompute(ws,\"multiservice\")\n",
    "\n",
    "# If deploying to a cluster configured for dev/test, ensure that it was created with enough\n",
    "# cores and memory to handle this deployment configuration. Note that memory is also used by\n",
    "# things such as dependencies and AML components.\n",
    "deployment_config = AksWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1,enable_app_insights=True)\n",
    "service = Model.deploy(ws, \"orderholdlatest\", [model] , inference_config, deployment_config, aks_target)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://13.67.176.88:80/api/v1/service/orderholdlatest/score\n"
     ]
    }
   ],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s05vytsqqzUQYgoE8DOzwOi9sK558cz6\n"
     ]
    }
   ],
   "source": [
    "primary, secondary = service.get_keys()\n",
    "print(primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
