{
    "cells":  [
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "Copyright (c) Microsoft Corporation. All rights reserved.\n",
                                     "\n",
                                     "Licensed under the MIT License."
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/automated-machine-learning/dataprep-remote-execution/auto-ml-dataprep-remote-execution.png)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "# Automated Machine Learning\n",
                                     "_**Prepare Data using `azureml.dataprep` for Remote Execution (AmlCompute)**_\n",
                                     "\n",
                                     "## Contents\n",
                                     "1. [Introduction](#Introduction)\n",
                                     "1. [Setup](#Setup)\n",
                                     "1. [Data](#Data)\n",
                                     "1. [Train](#Train)\n",
                                     "1. [Results](#Results)\n",
                                     "1. [Test](#Test)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Introduction\n",
                                     "In this example we showcase how you can use the `azureml.dataprep` SDK to load and prepare data for AutoML. `azureml.dataprep` can also be used standalone; full documentation can be found [here](https://github.com/Microsoft/PendletonDocs).\n",
                                     "\n",
                                     "Make sure you have executed the [configuration](../../../configuration.ipynb) before running this notebook.\n",
                                     "\n",
                                     "In this notebook you will learn how to:\n",
                                     "1. Define data loading and preparation steps in a `Dataflow` using `azureml.dataprep`.\n",
                                     "2. Pass the `Dataflow` to AutoML for a local run.\n",
                                     "3. Pass the `Dataflow` to AutoML for a remote run."
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Setup\n",
                                     "\n",
                                     "Currently, Data Prep only supports __Ubuntu 16__ and __Red Hat Enterprise Linux 7__. We are working on supporting more linux distros."
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "As part of the setup you have already created an Azure ML `Workspace` object. For AutoML you will need to create an `Experiment` object, which is a named object in a `Workspace` used to run experiments."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "import logging\n",
                                     "import time\n",
                                     "\n",
                                     "import pandas as pd\n",
                                     "\n",
                                     "import azureml.core\n",
                                     "from azureml.core.compute import DsvmCompute\n",
                                     "from azureml.core.experiment import Experiment\n",
                                     "from azureml.core.workspace import Workspace\n",
                                     "import azureml.dataprep as dprep\n",
                                     "from azureml.train.automl import AutoMLConfig"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "ws = Workspace.from_config()\n",
                                     " \n",
                                     "# choose a name for experiment\n",
                                     "experiment_name = \u0027automl-dataprep-remote-dsvm\u0027\n",
                                     "# project folder\n",
                                     "project_folder = \u0027./sample_projects/automl-dataprep-remote-dsvm\u0027\n",
                                     " \n",
                                     "experiment = Experiment(ws, experiment_name)\n",
                                     " \n",
                                     "output = {}\n",
                                     "output[\u0027SDK version\u0027] = azureml.core.VERSION\n",
                                     "output[\u0027Subscription ID\u0027] = ws.subscription_id\n",
                                     "output[\u0027Workspace Name\u0027] = ws.name\n",
                                     "output[\u0027Resource Group\u0027] = ws.resource_group\n",
                                     "output[\u0027Location\u0027] = ws.location\n",
                                     "output[\u0027Project Directory\u0027] = project_folder\n",
                                     "output[\u0027Experiment Name\u0027] = experiment.name\n",
                                     "pd.set_option(\u0027display.max_colwidth\u0027, -1)\n",
                                     "outputDf = pd.DataFrame(data = output, index = [\u0027\u0027])\n",
                                     "outputDf.T"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Data"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# You can use `auto_read_file` which intelligently figures out delimiters and datatypes of a file.\n",
                                     "# The data referenced here was a 1MB simple random sample of the Chicago Crime data into a local temporary directory.\n",
                                     "# You can also use `read_csv` and `to_*` transformations to read (with overridable delimiter)\n",
                                     "# and convert column types manually.\n",
                                     "example_data = \u0027https://dprepdata.blob.core.windows.net/demo/crime0-random.csv\u0027\n",
                                     "dflow = dprep.read_csv(example_data, infer_column_types=True)\n",
                                     "dflow.get_profile()"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# As `Primary Type` is our y data, we need to drop the values those are null in this column.\n",
                                     "dflow = dflow.drop_nulls(\u0027Primary Type\u0027)\n",
                                     "dflow.head(5)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "### Review the Data Preparation Result\n",
                                     "\n",
                                     "You can peek the result of a Dataflow at any range using `skip(i)` and `head(j)`. Doing so evaluates only `j` records for all the steps in the Dataflow, which makes it fast even against large datasets.\n",
                                     "\n",
                                     "`Dataflow` objects are immutable and are composed of a list of data preparation steps. A `Dataflow` object can be branched at any point for further usage."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "X = dflow.drop_columns(columns=[\u0027Primary Type\u0027, \u0027FBI Code\u0027])\n",
                                     "y = dflow.keep_columns(columns=[\u0027Primary Type\u0027], validate_column_exists=True)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Train\n",
                                     "\n",
                                     "This creates a general AutoML settings object applicable for both local and remote runs."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "automl_settings = {\n",
                                     "    \"iteration_timeout_minutes\" : 10,\n",
                                     "    \"iterations\" : 2,\n",
                                     "    \"primary_metric\" : \u0027AUC_weighted\u0027,\n",
                                     "    \"preprocess\" : True,\n",
                                     "    \"verbosity\" : logging.INFO\n",
                                     "}"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "### Create or Attach an AmlCompute cluster"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from azureml.core.compute import AmlCompute\n",
                                     "from azureml.core.compute import ComputeTarget\n",
                                     "\n",
                                     "# Choose a name for your cluster.\n",
                                     "amlcompute_cluster_name = \"cpu-cluster\"\n",
                                     "\n",
                                     "found = False\n",
                                     "\n",
                                     "# Check if this compute target already exists in the workspace.\n",
                                     "\n",
                                     "cts = ws.compute_targets\n",
                                     "if amlcompute_cluster_name in cts and cts[amlcompute_cluster_name].type == \u0027AmlCompute\u0027:\n",
                                     "    found = True\n",
                                     "    print(\u0027Found existing compute target.\u0027)\n",
                                     "    compute_target = cts[amlcompute_cluster_name]\n",
                                     "\n",
                                     "if not found:\n",
                                     "    print(\u0027Creating a new compute target...\u0027)\n",
                                     "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\", # for GPU, use \"STANDARD_NC6\"\n",
                                     "                                                                #vm_priority = \u0027lowpriority\u0027, # optional\n",
                                     "                                                                max_nodes = 6)\n",
                                     "\n",
                                     "    # Create the cluster.\\n\",\n",
                                     "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, provisioning_config)\n",
                                     "\n",
                                     "    # Can poll for a minimum number of nodes and for a specific timeout.\n",
                                     "    # If no min_node_count is provided, it will use the scale settings for the cluster.\n",
                                     "    compute_target.wait_for_completion(show_output = True, min_node_count = None, timeout_in_minutes = 20)\n",
                                     "\n",
                                     "     # For a more detailed view of current AmlCompute status, use get_status()."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from azureml.core.runconfig import RunConfiguration\n",
                                     "from azureml.core.conda_dependencies import CondaDependencies\n",
                                     "import pkg_resources\n",
                                     "\n",
                                     "# create a new RunConfig object\n",
                                     "conda_run_config = RunConfiguration(framework=\"python\")\n",
                                     "\n",
                                     "# Set compute target to AmlCompute\n",
                                     "conda_run_config.target = compute_target\n",
                                     "conda_run_config.environment.docker.enabled = True\n",
                                     "conda_run_config.environment.docker.base_image = azureml.core.runconfig.DEFAULT_CPU_IMAGE\n",
                                     "\n",
                                     "dprep_dependency = \u0027azureml-dataprep==\u0027 + pkg_resources.get_distribution(\"azureml-dataprep\").version\n",
                                     "\n",
                                     "cd = CondaDependencies.create(pip_packages=[\u0027azureml-sdk[automl]\u0027, dprep_dependency], conda_packages=[\u0027numpy\u0027,\u0027py-xgboost\u003c=0.80\u0027])\n",
                                     "conda_run_config.environment.python.conda_dependencies = cd"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "### Pass Data with `Dataflow` Objects\n",
                                     "\n",
                                     "The `Dataflow` objects captured above can also be passed to the `submit` method for a remote run. AutoML will serialize the `Dataflow` object and send it to the remote compute target. The `Dataflow` will not be evaluated locally."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "automl_config = AutoMLConfig(task = \u0027classification\u0027,\n",
                                     "                             debug_log = \u0027automl_errors.log\u0027,\n",
                                     "                             path = project_folder,\n",
                                     "                             run_configuration=conda_run_config,\n",
                                     "                             X = X,\n",
                                     "                             y = y,\n",
                                     "                             **automl_settings)"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "remote_run = experiment.submit(automl_config, show_output = True)"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "remote_run"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "### Pre-process cache cleanup\n",
                                     "The preprocess data gets cache at user default file store. When the run is completed the cache can be cleaned by running below cell"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "remote_run.clean_preprocessor_cache()"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "### Cancelling Runs\n",
                                     "You can cancel ongoing remote runs using the `cancel` and `cancel_iteration` functions."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Cancel the ongoing experiment and stop scheduling new iterations.\n",
                                     "# remote_run.cancel()\n",
                                     "\n",
                                     "# Cancel iteration 1 and move onto iteration 2.\n",
                                     "# remote_run.cancel_iteration(1)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Results"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "#### Widget for Monitoring Runs\n",
                                     "\n",
                                     "The widget will first report a \"loading\" status while running the first iteration. After completing the first iteration, an auto-updating graph and table will be shown. The widget will refresh once per minute, so you should see the graph update as child runs complete.\n",
                                     "\n",
                                     "**Note:** The widget displays a link at the bottom. Use this link to open a web interface to explore the individual run details."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from azureml.widgets import RunDetails\n",
                                     "RunDetails(remote_run).show()"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "#### Retrieve All Child Runs\n",
                                     "You can also use SDK methods to fetch all the child runs and see individual metrics that we log."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "children = list(remote_run.get_children())\n",
                                     "metricslist = {}\n",
                                     "for run in children:\n",
                                     "    properties = run.get_properties()\n",
                                     "    metrics = {k: v for k, v in run.get_metrics().items() if isinstance(v, float)}\n",
                                     "    metricslist[int(properties[\u0027iteration\u0027])] = metrics\n",
                                     "    \n",
                                     "rundata = pd.DataFrame(metricslist).sort_index(1)\n",
                                     "rundata"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "### Retrieve the Best Model\n",
                                     "\n",
                                     "Below we select the best pipeline from our iterations. The `get_output` method returns the best run and the fitted model. Overloads on `get_output` allow you to retrieve the best run and fitted model for *any* logged metric or for a particular *iteration*."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "best_run, fitted_model = remote_run.get_output()\n",
                                     "print(best_run)\n",
                                     "print(fitted_model)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "#### Best Model Based on Any Other Metric\n",
                                     "Show the run and the model that has the smallest `log_loss` value:"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "lookup_metric = \"log_loss\"\n",
                                     "best_run, fitted_model = remote_run.get_output(metric = lookup_metric)\n",
                                     "print(best_run)\n",
                                     "print(fitted_model)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "#### Model from a Specific Iteration\n",
                                     "Show the run and the model from the first iteration:"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "iteration = 0\n",
                                     "best_run, fitted_model = remote_run.get_output(iteration = iteration)\n",
                                     "print(best_run)\n",
                                     "print(fitted_model)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Test\n",
                                     "\n",
                                     "#### Load Test Data\n",
                                     "For the test data, it should have the same preparation step as the train data. Otherwise it might get failed at the preprocessing step."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "dflow_test = dprep.auto_read_file(path=\u0027https://dprepdata.blob.core.windows.net/demo/crime0-test.csv\u0027).skip(1)\n",
                                     "dflow_test = dflow_test.drop_nulls(\u0027Primary Type\u0027)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "#### Testing Our Best Fitted Model\n",
                                     "We will use confusion matrix to see how our model works."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from pandas_ml import ConfusionMatrix\n",
                                     "\n",
                                     "y_test = dflow_test.keep_columns(columns=[\u0027Primary Type\u0027]).to_pandas_dataframe()\n",
                                     "X_test = dflow_test.drop_columns(columns=[\u0027Primary Type\u0027, \u0027FBI Code\u0027]).to_pandas_dataframe()\n",
                                     "\n",
                                     "\n",
                                     "ypred = fitted_model.predict(X_test)\n",
                                     "\n",
                                     "cm = ConfusionMatrix(y_test[\u0027Primary Type\u0027], ypred)\n",
                                     "\n",
                                     "print(cm)\n",
                                     "\n",
                                     "cm.plot()"
                                 ]
                  }
              ],
    "metadata":  {
                     "authors":  [
                                     {
                                         "name":  "savitam"
                                     }
                                 ],
                     "kernelspec":  {
                                        "display_name":  "Python 3.6 - AzureML",
                                        "language":  "python",
                                        "name":  "python3-azureml"
                                    },
                     "language_info":  {
                                           "codemirror_mode":  {
                                                                   "name":  "ipython",
                                                                   "version":  3
                                                               },
                                           "file_extension":  ".py",
                                           "mimetype":  "text/x-python",
                                           "name":  "python",
                                           "nbconvert_exporter":  "python",
                                           "pygments_lexer":  "ipython3",
                                           "version":  "3.6.5"
                                       },
                     "categories":  [
                                        "how-to-use-azureml",
                                        "automated-machine-learning"
                                    ]
                 },
    "nbformat":  4,
    "nbformat_minor":  2
}