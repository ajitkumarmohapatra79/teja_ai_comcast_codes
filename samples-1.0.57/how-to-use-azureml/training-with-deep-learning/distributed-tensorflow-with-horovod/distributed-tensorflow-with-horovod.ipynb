{
    "cells":  [
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "Copyright (c) Microsoft Corporation. All rights reserved.\n",
                                     "\n",
                                     "Licensed under the MIT License."
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/training/manage-runs/manage-runs.png)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "# Distributed Tensorflow with Horovod\n",
                                     "In this tutorial, you will train a word2vec model in TensorFlow using distributed training via [Horovod](https://github.com/uber/horovod)."
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Prerequisites\n",
                                     "* Understand the [architecture and terms](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture) introduced by Azure Machine Learning (AML)\n",
                                     "* If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, go through the [configuration notebook](../../../configuration.ipynb) to:\n",
                                     "    * install the AML SDK\n",
                                     "    * create a workspace and its configuration file (`config.json`)\n",
                                     "* Review the [tutorial](../train-hyperparameter-tune-deploy-with-tensorflow/train-hyperparameter-tune-deploy-with-tensorflow.ipynb) on single-node TensorFlow training using the SDK"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Check core SDK version number\n",
                                     "import azureml.core\n",
                                     "\n",
                                     "print(\"SDK version:\", azureml.core.VERSION)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Diagnostics\n",
                                     "Opt-in diagnostics for better experience, quality, and security of future releases."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {
                                       "tags":  [
                                                    "Diagnostics"
                                                ]
                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from azureml.telemetry import set_diagnostics_collection\n",
                                     "\n",
                                     "set_diagnostics_collection(send_diagnostics=True)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Initialize workspace\n",
                                     "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from azureml.core.workspace import Workspace\n",
                                     "\n",
                                     "ws = Workspace.from_config()\n",
                                     "print(\u0027Workspace name: \u0027 + ws.name, \n",
                                     "      \u0027Azure region: \u0027 + ws.location, \n",
                                     "      \u0027Subscription id: \u0027 + ws.subscription_id, \n",
                                     "      \u0027Resource group: \u0027 + ws.resource_group, sep=\u0027\\n\u0027)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Create or Attach existing AmlCompute\n",
                                     "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for training your model. In this tutorial, you create `AmlCompute` as your training compute resource.\n",
                                     "\n",
                                     "**Creation of AmlCompute takes approximately 5 minutes.** If the AmlCompute with that name is already in your workspace this code will skip the creation process.\n",
                                     "\n",
                                     "As with other Azure services, there are limits on certain resources (e.g. AmlCompute) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from azureml.core.compute import ComputeTarget, AmlCompute\n",
                                     "from azureml.core.compute_target import ComputeTargetException\n",
                                     "\n",
                                     "# choose a name for your cluster\n",
                                     "cluster_name = \"gpu-cluster\"\n",
                                     "\n",
                                     "try:\n",
                                     "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
                                     "    print(\u0027Found existing compute target\u0027)\n",
                                     "except ComputeTargetException:\n",
                                     "    print(\u0027Creating a new compute target...\u0027)\n",
                                     "    compute_config = AmlCompute.provisioning_configuration(vm_size=\u0027STANDARD_NC6\u0027, \n",
                                     "                                                           max_nodes=4)\n",
                                     "\n",
                                     "    # create the cluster\n",
                                     "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
                                     "\n",
                                     "    compute_target.wait_for_completion(show_output=True)\n",
                                     "\n",
                                     "# use get_status() to get a detailed status for the current cluster. \n",
                                     "print(compute_target.get_status().serialize())"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "The above code creates a GPU cluster. If you instead want to create a CPU cluster, provide a different VM size to the `vm_size` parameter, such as `STANDARD_D2_V2`."
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Upload data to datastore\n",
                                     "To make data accessible for remote training, AML provides a convenient way to do so via a [Datastore](https://docs.microsoft.com/azure/machine-learning/service/how-to-access-data). The datastore provides a mechanism for you to upload/download data to Azure Storage, and interact with it from your remote compute targets. \n",
                                     "\n",
                                     "If your data is already stored in Azure, or you download the data as part of your training script, you will not need to do this step. For this tutorial, although you can download the data in your training script, we will demonstrate how to upload the training data to a datastore and access it during training to illustrate the datastore functionality."
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "First, download the training data from [here](http://mattmahoney.net/dc/text8.zip) to your local machine:"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "import os\n",
                                     "import urllib\n",
                                     "\n",
                                     "os.makedirs(\u0027./data\u0027, exist_ok=True)\n",
                                     "download_url = \u0027http://mattmahoney.net/dc/text8.zip\u0027\n",
                                     "urllib.request.urlretrieve(download_url, filename=\u0027./data/text8.zip\u0027)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "Each workspace is associated with a default datastore. In this tutorial, we will upload the training data to this default datastore."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "ds = ws.get_default_datastore()\n",
                                     "print(ds.datastore_type, ds.account_name, ds.container_name)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "Upload the contents of the data directory to the path `./data` on the default datastore."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "ds.upload(src_dir=\u0027data\u0027, target_path=\u0027data\u0027, overwrite=True, show_progress=True)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "For convenience, let\u0027s get a reference to the path on the datastore with the zip file of training data. We can do so using the `path` method. In the next section, we can then pass this reference to our training script\u0027s `--input_data` argument. "
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "path_on_datastore = \u0027data/text8.zip\u0027\n",
                                     "ds_data = ds.path(path_on_datastore)\n",
                                     "print(ds_data)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Train model on the remote compute"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "### Create a project directory\n",
                                     "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script, and any additional files your training script depends on."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "project_folder = \u0027./tf-distr-hvd\u0027\n",
                                     "os.makedirs(project_folder, exist_ok=True)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "Copy the training script `tf_horovod_word2vec.py` into this project directory."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "import shutil\n",
                                     "\n",
                                     "shutil.copy(\u0027tf_horovod_word2vec.py\u0027, project_folder)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "### Create an experiment\n",
                                     "Create an [Experiment](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment) to track all the runs in your workspace for this distributed TensorFlow tutorial. "
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from azureml.core import Experiment\n",
                                     "\n",
                                     "experiment_name = \u0027tf-distr-hvd\u0027\n",
                                     "experiment = Experiment(ws, name=experiment_name)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "### Create a TensorFlow estimator\n",
                                     "The AML SDK\u0027s TensorFlow estimator enables you to easily submit TensorFlow training jobs for both single-node and distributed runs. For more information on the TensorFlow estimator, refer [here](https://docs.microsoft.com/azure/machine-learning/service/how-to-train-tensorflow).\n",
                                     "\n",
                                     "The TensorFlow estimator also takes a `framework_version` parameter -- if no version is provided, the estimator will default to the latest version supported by AzureML. Use `TensorFlow.get_supported_versions()` to get a list of all versions supported by your current SDK version or see the [SDK documentation](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.dnn?view=azure-ml-py) for the versions supported in the most current release."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from azureml.core.runconfig import MpiConfiguration\n",
                                     "from azureml.train.dnn import TensorFlow\n",
                                     "\n",
                                     "script_params={\n",
                                     "    \u0027--input_data\u0027: ds_data\n",
                                     "}\n",
                                     "\n",
                                     "estimator= TensorFlow(source_directory=project_folder,\n",
                                     "                      compute_target=compute_target,\n",
                                     "                      script_params=script_params,\n",
                                     "                      entry_script=\u0027tf_horovod_word2vec.py\u0027,\n",
                                     "                      node_count=2,\n",
                                     "                      distributed_training=MpiConfiguration(),\n",
                                     "                      framework_version=\u00271.13\u0027)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "The above code specifies that we will run our training script on `2` nodes, with one worker per node. In order to execute a distributed run using MPI/Horovod, you must provide the argument `distributed_backend=\u0027mpi\u0027`. Using this estimator with these settings, TensorFlow, Horovod and their dependencies will be installed for you. However, if your script also uses other packages, make sure to install them via the `TensorFlow` constructor\u0027s `pip_packages` or `conda_packages` parameters.\n",
                                     "\n",
                                     "Note that we passed our training data reference `ds_data` to our script\u0027s `--input_data` argument. This will 1) mount our datastore on the remote compute and 2) provide the path to the data zip file on our datastore."
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "### Submit job\n",
                                     "Run your experiment by submitting your estimator object. Note that this call is asynchronous."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "run = experiment.submit(estimator)\n",
                                     "print(run)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "### Monitor your run\n",
                                     "You can monitor the progress of the run with a Jupyter widget. Like the run submission, the widget is asynchronous and provides live updates every 10-15 seconds until the job completes."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from azureml.widgets import RunDetails\n",
                                     "RunDetails(run).show()"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "Alternatively, you can block until the script has completed training before running more code."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "run.wait_for_completion(show_output=True)"
                                 ]
                  }
              ],
    "metadata":  {
                     "authors":  [
                                     {
                                         "name":  "roastala"
                                     }
                                 ],
                     "kernelspec":  {
                                        "display_name":  "Python 3.6 - AzureML",
                                        "language":  "python",
                                        "name":  "python3-azureml"
                                    },
                     "language_info":  {
                                           "codemirror_mode":  {
                                                                   "name":  "ipython",
                                                                   "version":  3
                                                               },
                                           "file_extension":  ".py",
                                           "mimetype":  "text/x-python",
                                           "name":  "python",
                                           "nbconvert_exporter":  "python",
                                           "pygments_lexer":  "ipython3",
                                           "version":  "3.6.6"
                                       },
                     "categories":  [
                                        "how-to-use-azureml",
                                        "training-with-deep-learning"
                                    ]
                 },
    "nbformat":  4,
    "nbformat_minor":  2
}